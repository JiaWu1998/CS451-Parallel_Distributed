-Compile with: 
gcc -o gauss_omp gauss_openMP.c -fopenmp

-Test with: 
./gauss_omp <matrix-dimensions> <random-seed>

-My Performance Test:
./gauss_omp 2000 <random seed>

-Optimization:
version 1: I tried to parallelize everything within the
norm for loop.

version 2: I tried to parallelize the norm loop and also 
the col loop. However, the performance went down. 
(Performance: ~2400ms)

version 3: I went back to version 1. I just played with the
number of threads. 
# of threads=15 (Performance: ~660ms)
# of threads=30 (Performance: ~620ms)
# of threads=40 (Performance: ~480ms)
# of threads=50 (Performance: ~740ms)
# of threads=60 (Performance: ~730ms)

Zone in
# of threads=35 (Performance: ~540ms)
# of threads=45 (Performance: ~430ms)
# of threads=48 (Performance: ~420ms)
# of threads=49 (Performance: ~740ms)

Magic number is 48 threads.

Scability Test:
I am testing with n=1000 to see if my solution is scalable.
# of threads=48 (Performance: ~70ms)

-Final Performance: ~420ms 
*7800ms for running serially with n=2000
*972ms for running serially with n=1000

-I think the current version is efficient 
because it has a speed up of 7800/420 = 18.57 
which makes it 18.6 times faster than the serial program.
My program is also scalable since the relatively
speed up is proportional to the size of the problem set. 
Note that the speed up for n=1000 is 972/70 = 13.88.
